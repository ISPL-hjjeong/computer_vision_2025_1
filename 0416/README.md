# ğŸ¯ ê³¼ì œ1. SORT ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•œ ë‹¤ì¤‘ ê°ì²´ ì¶”ì ê¸° êµ¬í˜„

ì´ í”„ë¡œì íŠ¸ëŠ” [YOLOv4](https://github.com/AlexeyAB/darknet)ì™€ [SORT (Simple Online and Realtime Tracking)](https://github.com/abewley/sort) ì•Œê³ ë¦¬ì¦˜ì„ ê²°í•©í•˜ì—¬ ë¹„ë””ì˜¤ ë‚´ ë‹¤ì¤‘ ê°ì²´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì í•˜ëŠ” ì‹œìŠ¤í…œì„ êµ¬í˜„í•©ë‹ˆë‹¤.

![image](https://github.com/user-attachments/assets/439f1ac5-a7d3-4bcd-9a35-fa50c444c256)

## ğŸ“Œ í”„ë¡œì íŠ¸ ì„¤ëª…

ì´ ì‹¤ìŠµì—ì„œëŠ” SORT ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ì—ì„œ ë‹¤ì¤‘ ê°ì²´ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì í•˜ëŠ” í”„ë¡œê·¸ë¨ì„ êµ¬í˜„í•©ë‹ˆë‹¤.  
ì´ë¥¼ í†µí•´ ê°ì²´ ì¶”ì ì˜ ê¸°ë³¸ ê°œë…ê³¼ SORT ì•Œê³ ë¦¬ì¦˜ì˜ ì ìš© ë°©ë²•ì„ í•™ìŠµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## âœ… ìš”êµ¬ì‚¬í•­

- **ê°ì²´ ê²€ì¶œê¸° êµ¬í˜„**: YOLOv4ì™€ ê°™ì€ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê° í”„ë ˆì„ì—ì„œ ê°ì²´ë¥¼ ê²€ì¶œí•©ë‹ˆë‹¤.
- **SORT ì¶”ì ê¸° ì´ˆê¸°í™”**: ê²€ì¶œëœ ê°ì²´ì˜ ê²½ê³„ ìƒìë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ SORTë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.
- **ê°ì²´ ì¶”ì  ìœ ì§€**: ê° í”„ë ˆì„ë§ˆë‹¤ ê²€ì¶œëœ ê°ì²´ì™€ ê¸°ì¡´ ì¶”ì  ê°ì²´ë¥¼ ì—°ê´€ì‹œì¼œ ì¶”ì ì„ ìœ ì§€í•©ë‹ˆë‹¤.
- **ê²°ê³¼ ì‹œê°í™”**: ì¶”ì ëœ ê°ì²´ì— ê³ ìœ  IDë¥¼ ë¶€ì—¬í•˜ê³ , í•´ë‹¹ IDì™€ ê²½ê³„ ìƒìë¥¼ ë¹„ë””ì˜¤ì— ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.

## ğŸ’¡ íŒíŠ¸

- OpenCVì˜ DNN ëª¨ë“ˆë¡œ YOLOv4 ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤.
- SORTëŠ” ì¹¼ë§Œ í•„í„° ë° í—ê°€ë¦¬ì•ˆ ì•Œê³ ë¦¬ì¦˜ì„ í™œìš©í•˜ì—¬ ì¶”ì  ìƒíƒœë¥¼ ì˜ˆì¸¡í•˜ê³  ì—°ê´€ì‹œí‚µë‹ˆë‹¤.
- ì •í™•í•œ appearance ì¶”ì ì´ í•„ìš”í•  ê²½ìš° [Deep SORT](https://github.com/nwojke/deep_sort) ê°™ì€ í™•ì¥ ë²„ì „ì„ ê³ ë ¤í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ğŸ§  ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬

- `OpenCV`: ë¹„ë””ì˜¤ ì²˜ë¦¬ ë° DNN ê¸°ë°˜ ê°ì²´ ê²€ì¶œ
- `NumPy`: ìˆ˜ì¹˜ ì—°ì‚°
- `SORT`: ê°ì²´ ì¶”ì  ì•Œê³ ë¦¬ì¦˜


## ğŸ§ª ì½”ë“œ ì„¤ëª… (main.py)

### YOLOv4 ì„¤ì •
```
config_path = "yolov4.cfg"
weights_path = "yolov4.weights"
names_path = "coco.names"
```
### í´ë˜ìŠ¤ ì´ë¦„ ë¶ˆëŸ¬ì˜¤ê¸°
```
with open(names_path, 'r') as f:
    classes = f.read().strip().split('\n')
```
### YOLOv4 ëª¨ë¸ ë¡œë“œ
```
net = cv2.dnn.readNetFromDarknet(config_path, weights_path)
net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
```
### ì¶œë ¥ ë ˆì´ì–´ ì´ë¦„ ì¶”ì¶œ
```
layer_names = net.getLayerNames()
output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]
```
### SORT ì¶”ì ê¸° ì´ˆê¸°í™”
```
tracker = Sort()
```
### ë¹„ë””ì˜¤ ì—´ê¸°
```
cap = cv2.VideoCapture("video.mp4")

while True:
    ret, frame = cap.read()
    if not ret:
        break

    h, w = frame.shape[:2]
```
### YOLOv4 ê°ì²´ ê²€ì¶œ
```
    blob = cv2.dnn.blobFromImage(frame, 1/255.0, (416, 416), swapRB=True, crop=False)
    net.setInput(blob)
    outputs = net.forward(output_layers)

    boxes, confidences, class_ids = [], [], []

    for output in outputs:
        for detection in output:
            scores = detection[5:]
            class_id = np.argmax(scores)
            confidence = scores[class_id]
            if confidence > 0.4:
                cx, cy, bw, bh = detection[0:4] * np.array([w, h, w, h])
                x, y = int(cx - bw/2), int(cy - bh/2)
                boxes.append([x, y, int(bw), int(bh)])
                confidences.append(float(confidence))
                class_ids.append(class_id)

    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.4, 0.3)
    detections = []

    if len(indices) > 0:
        for i in indices.flatten():
            x, y, bw, bh = boxes[i]
            detections.append([x, y, x + bw, y + bh, confidences[i]])

    dets = np.array(detections)
    tracks = tracker.update(dets)

    for track in tracks:
        x1, y1, x2, y2, track_id = track.astype(int)
        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(frame, f'ID {int(track_id)}', (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)

    cv2.imshow("SORT Tracker", frame)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
```

## ğŸ¥ ì‹¤í–‰ ê²°ê³¼
ì‹¤í–‰ ì‹œ, ì¶”ì ëœ ê°ì²´ì— ê³ ìœ  IDê°€ í• ë‹¹ë˜ê³  ë¹„ë””ì˜¤ í”„ë ˆì„ì— ì‚¬ê°í˜•ê³¼ í•¨ê»˜ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.

----


# ğŸ‘¤ ê³¼ì œ2. Mediapipeë¥¼ í™œìš©í•œ ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ ë° ì‹œê°í™”

ì´ í”„ë¡œì íŠ¸ëŠ” Googleì˜ [Mediapipe](https://google.github.io/mediapipe/) ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ **ì‹¤ì‹œê°„ìœ¼ë¡œ ì–¼êµ´ì˜ 468ê°œ ëœë“œë§ˆí¬ë¥¼ ì¶”ì¶œí•˜ê³  ì‹œê°í™”**í•˜ëŠ” í”„ë¡œê·¸ë¨ì„ êµ¬í˜„í•œ ì˜ˆì œì…ë‹ˆë‹¤.

![image](https://github.com/user-attachments/assets/d92a80b3-4a32-475c-abe4-f2aa544838dc)

## ğŸ“Œ í”„ë¡œì íŠ¸ ì„¤ëª…

- Mediapipeì˜ FaceMesh ëª¨ë“ˆì„ ì‚¬ìš©í•´ ì›¹ìº ìœ¼ë¡œë¶€í„° ì…ë ¥ë˜ëŠ” ì˜ìƒì—ì„œ ì–¼êµ´ì„ ê²€ì¶œí•˜ê³ , 468ê°œì˜ ì •ë°€í•œ ëœë“œë§ˆí¬ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤.
- ì¶”ì¶œëœ ëœë“œë§ˆí¬ëŠ” `OpenCV`ì˜ ê·¸ë¦¬ê¸° ìœ í‹¸ì„ ì‚¬ìš©í•´ í™”ë©´ì— ì ê³¼ ì„ ìœ¼ë¡œ ì‹œê°í™”ë©ë‹ˆë‹¤.
- ESC í‚¤ë¥¼ ëˆ„ë¥´ë©´ í”„ë¡œê·¸ë¨ì´ ì¢…ë£Œë©ë‹ˆë‹¤.

## âœ… ìš”êµ¬ì‚¬í•­

- Mediapipe FaceMesh ëª¨ë“ˆì„ ì´ˆê¸°í™”í•˜ê³  ì–¼êµ´ ëœë“œë§ˆí¬ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ê²€ì¶œí•©ë‹ˆë‹¤.
- OpenCVë¥¼ í†µí•´ ì›¹ìº  ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë° ë° í™”ë©´ ì¶œë ¥ ê¸°ëŠ¥ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
- ê²€ì¶œëœ 468ê°œ ì–¼êµ´ ëœë“œë§ˆí¬ë¥¼ ì  ë˜ëŠ” ì—°ê²°ì„ ìœ¼ë¡œ ì‹œê°í™”í•©ë‹ˆë‹¤.

## ğŸ§  ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬

- [`mediapipe`](https://pypi.org/project/mediapipe/): ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ
- [`opencv-python`](https://pypi.org/project/opencv-python/): ì˜ìƒ ì²˜ë¦¬ ë° UI

## ğŸ§ª ì½”ë“œ ì„¤ëª…

### FaceMesh ëª¨ë“ˆ ì´ˆê¸°í™”
```
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(
    static_image_mode=False,
    max_num_faces=1,
    refine_landmarks=True,
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)
```
### ëœë“œë§ˆí¬ ìŠ¤íƒ€ì¼ ì •ì˜
```
mp_drawing = mp.solutions.drawing_utils
drawing_spec = mp_drawing.DrawingSpec(thickness=1, circle_radius=1, color=(0, 255, 0))
```
### ì›¹ìº  ì˜ìƒ ìŠ¤íŠ¸ë¦¬ë°
```
cap = cv2.VideoCapture(0)

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame = cv2.flip(frame, 1)  # ì¢Œìš° ë°˜ì „
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
```
### ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ
```
results = face_mesh.process(rgb_frame)
```
### ì–¼êµ´ì— ëœë“œë§ˆí¬ í‘œì‹œ
```
    if results.multi_face_landmarks:
        for face_landmarks in results.multi_face_landmarks:
            mp_drawing.draw_landmarks(
                image=frame,
                landmark_list=face_landmarks,
                connections=mp_face_mesh.FACEMESH_TESSELATION,
                landmark_drawing_spec=drawing_spec,
                connection_drawing_spec=drawing_spec
            )

    cv2.imshow('FaceMesh Landmarks', frame)
```

## ğŸ–¼ï¸ ì‹¤í–‰ ê²°ê³¼

ì–¼êµ´ì— 468ê°œì˜ ëœë“œë§ˆí¬ê°€ ì ê³¼ ì—°ê²°ì„  í˜•íƒœë¡œ ì‹¤ì‹œê°„ìœ¼ë¡œ í‘œì‹œë©ë‹ˆë‹¤.
